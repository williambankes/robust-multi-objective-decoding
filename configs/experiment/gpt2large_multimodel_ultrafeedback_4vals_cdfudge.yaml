# @package _global_
defaults:
  - override /model: gpt_2_large_multi_model
  - override /ref_model: gemma_2_2b_it

dataset:
  _target_: robust_multi_objective_decoding.data.multiobjective_dataset.MultiObjectiveDataset
  data_path: YOUR_DATA_PATH
  labels:
    - 'reward_ultrafeedback-instruction_following'
    - 'reward_ultrafeedback-truthfulness'
    - 'reward_ultrafeedback-honesty'
    - 'reward_ultrafeedback-helpfulness'
  train_test_val_split:
    - 0.8
    - 0.195
    - 0.005
  response_name: response
  apply_prompt_template: False
  balance_dataset: False

trainer:
  max_epochs: 1

dataloader:
  train:
    _target_: torch.utils.data.DataLoader
    batch_size: 2
    num_workers: 4
    pin_memory: True
    shuffle: True

collate_fn: 
  _target_: robust_multi_objective_decoding.data.multi_obj_collate_functions.create_collate_functions
  reward_collations:
    - 'eos'
    - 'eos'
    - 'eos'
    - 'eos'
  rand_len: True

model:
  num_heads: 4 # 1

tokenizer:
  max_length: 1024 # 1024 for gpt2
  padding_side: 'left'

learner:
  _target_: robust_multi_objective_decoding.value_function_learner.MultiObjectiveValueFunctionLearner
  losses: 
    - _target_: robust_multi_objective_decoding.losses.MonteCarloLoss
    - _target_: robust_multi_objective_decoding.losses.MonteCarloLoss
    - _target_: robust_multi_objective_decoding.losses.MonteCarloLoss
    - _target_: robust_multi_objective_decoding.losses.MonteCarloLoss
  update_q_hat_every: 10

# Eval script points
checkpoint_path: YOUR_CHECKPOINT_PATH
max_new_tokens: 128
score_and_generate: True
seed: 42
test: False
experiment_folder: "sample"

# decoder: 
#   _target_: robust_multi_objective_decoding.decoders.blockwise_robust_decoder.BlockwiseRobustDecoder
#   lambda_coef: 1.0
#   num_branches: 16
#   tree_depth: 16
#   minibatch_size: 16
#   use_chat_format: False
#   vf_use_chat_template: False

decoder: 
  _target_: robust_multi_objective_decoding.decoders.multi_obj_controlled_decoder.MultiObjectiveControlledDecoder
  num_branches: 1
  weights: [0.25, 0.25, 0.25, 0.25]
  tree_depth: 10

oracle:
  _target_: robust_multi_objective_decoding.oracles.armoRM.ArmoRMOracle
  attribute_indices:
   - 6
   - 7
   - 8
   - 9
  cache_dir: YOUR_CACHE_PATH
  mode: rewards
  orcales: null # we set this to override the default MultiOracle 

use_vllm: True
base_gpu_use: 0.5